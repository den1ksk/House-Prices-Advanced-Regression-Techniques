#### Английская версия | [Конкурс Kaggle](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)

# Цены на жилье - Продвинутые методы регрессии

### Описание конкурса

Попросите покупателя описать дом своей мечты, и он, скорее всего, не начнет с высоты потолка в подвале или близости к железной дороге, идущей с востока на запад. Но набор данных этого конкурса игровых площадок доказывает, что на переговоры о цене влияет гораздо больше, чем количество спален или забор с белой калиткой. С помощью 79 объясняющих переменных, описывающих (почти) все аспекты жилых домов в Эймсе, штат Айова, в этом конкурсе вам предстоит предсказать окончательную цену каждого дома.

### Цель
Ваша задача - предсказать цену продажи для каждого дома. Для каждого идентификатора в тестовом наборе вы должны предсказать значение переменной SalePrice.

### Подход

В этом проекте для прогнозирования цен на жилье используется машинное обучение. Были предприняты следующие шаги:

1. **Анализ данных:**
   - Наборы данных для обучения и тестирования были загружены и тщательно изучены, чтобы понять характеристики и другие распределения. 
   - Проведя корреляционный анализ, мы определили ключевые характеристики, влияющие на цену продажи. Затем эти характеристики были визуализированы с помощью гистограмм и точечных диаграмм, что позволило получить более четкое представление об их влиянии.

2. **Разработка функциональных возможностей:**
   - Были разработаны новые функции для повышения точности прогнозирования модели, включая объединение существующих функций и создание бинарных индикаторов для конкретных характеристик.

3. Предварительная обработка данных.:**
   - Пропущенные значения были обработаны путем их сопоставления с помощью соответствующих стратегий, таких как заполнение "Нет" для категориальных признаков и "0" для числовых признаков.
   - Категориальные признаки были закодированы с использованием одноразового кодирования для преобразования их в числовые представления, подходящие для алгоритмов машинного обучения.

4. **Выбор модели и обучение:**
   - XGBRegressor и Ridge Regression были выбраны в качестве базовых моделей на основе их производительности и характеристик.
   - Модель Stacking Regressor была выбрана за ее способность сочетать преимущества нескольких базовых моделей.

5. **Оценка модели:**
   - Обученная модель была оценена с использованием показателей среднеквадратичной ошибки (RMSE) и R-квадрата (R2).
   - Был создан график баланса и график вероятности, чтобы оценить остаточные значения модели и убедиться, что они соответствуют нормальному распределению.

6. **Прогнозирование и представление данных:**
   - Обученная модель использовалась для прогнозирования цены продажи домов в тестовом наборе данных.
   - Затем прогнозы были преобразованы обратно в исходный масштаб путем применения обратного логарифмического преобразования.
   - Окончательные прогнозы были сохранены в файле заявки в требуемом формате для участия в конкурсе Kaggle.

### Результаты

Разработанная модель получила оценку Kaggle, равную **0.11996**, что позволило ей войти в **топ-5% ** в таблице лидеров. RMSE:0,0577, R2: 0,979

### Files

- `House_Prices.ipynb.ipynb`: Записная книжка Jupyter, содержащая полный код и анализ.
- `train.csv`: Набор данных для обучения.
- `test.csv`: Тестовый набор данных.
- `data_description.txt`: Описание функций в наборе данных.
- `submission.csv`: Файл, содержащий прогнозы для тестового набора данных.
- `png`: Все графики в проекте.

### Используемые библиотеки

- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn 
- xgboost
- scipy

### Благодарности

Этот проект был завершен в рамках конкурса Kaggle. Спасибо Kaggle и организаторам конкурса за предоставление набора данных и платформы.
